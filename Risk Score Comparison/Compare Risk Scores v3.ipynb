{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b31b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "import scipy\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import * \n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb59510",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd45c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Labels\n",
    "escapeLabels  = pd.read_csv(\"../Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "bestLabels  = pd.read_csv(\"Preprocessed Data/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index() #labels for prediction classes \n",
    "hfactionLabels  = pd.read_csv(\"Preprocessed Data/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index() #labels for prediction classes \n",
    "guideLabels  = pd.read_csv(\"Preprocessed Data/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index() #labels for prediction classes \n",
    "cardShockLabels = pd.read_csv(\"../Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"../Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "# Loading scores with mortality labels\n",
    "escapeHemoScores = pd.read_csv(\"../Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "cardShockHemoScores = pd.read_csv(\"../Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "serialHemoScores = pd.read_csv(\"../Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "\n",
    "escapeAllScores = pd.read_csv(\"../Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "hfactionAllScores = pd.read_csv(\"../Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "bestAllScores = pd.read_csv(\"../Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n",
    "guideAllScores = pd.read_csv(\"../Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()['ScoreDeath']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728299e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac95692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLabels(data, labels):\n",
    "    lst = []\n",
    "    idx = sorted(data.index)\n",
    "    for i in idx:\n",
    "        lab = labels.loc[i]\n",
    "        lst.append(lab['Death'])\n",
    "        \n",
    "    return pd.DataFrame(lst, columns=['Real'],index=idx)\n",
    "\n",
    "\n",
    "def convertCARNAEscape(data, scores, missing):\n",
    "    lst = []\n",
    "    for r in range(len(data)):\n",
    "        row = data.iloc[r]\n",
    "        idx = row.name\n",
    "        \n",
    "        if idx in missing:\n",
    "            lst.append(np.nan)\n",
    "        else:\n",
    "            if type(scores.loc[idx]) == pd.Series:\n",
    "                s = max(scores.loc[idx])\n",
    "            else:\n",
    "                s = scores.loc[idx]\n",
    "            \n",
    "            #convert score to prob value\n",
    "            lst.append(CARNAScoreVals(s))\n",
    "\n",
    "            \n",
    "    return lst\n",
    "\n",
    "def convertCARNA(data, scores, missing):\n",
    "    lst = []\n",
    "    idx = sorted(set(data.index))\n",
    "    \n",
    "    for i in idx:\n",
    "        if i in missing:\n",
    "            for row in range(len(data.loc[i])):\n",
    "                lst.append(np.nan)\n",
    "        else:\n",
    "            \n",
    "            sRows = scores.loc[i]\n",
    "            \n",
    "            try:\n",
    "                sRowLen = len(sRows)\n",
    "            except:\n",
    "                sRowLen = 1\n",
    "            \n",
    "            if type(data.loc[i]) == pd.Series: #just do once\n",
    "                \n",
    "                if type(sRows) == pd.Series:\n",
    "                    s = max(sRows)\n",
    "                else:\n",
    "                    s = sRows\n",
    "                \n",
    "                #convert score to prob value\n",
    "                lst.append(CARNAScoreVals(s))\n",
    "            \n",
    "            else:\n",
    "                for row in range(len(data.loc[i])):\n",
    "                    if row >= sRowLen:\n",
    "                        lst.append(np.nan)\n",
    "                    else:\n",
    "\n",
    "                        if sRowLen == 1:\n",
    "                            s = sRows\n",
    "                        else:\n",
    "                            s = sRows.iloc[row]\n",
    "\n",
    "                        #convert score to prob value\n",
    "                        lst.append(CARNAScoreVals(s))\n",
    "                                        \n",
    "    return lst\n",
    "\n",
    "def CARNAScoreVals(s):\n",
    "    if s == 5:\n",
    "        return 0.5\n",
    "    elif s == 4:\n",
    "        return 0.35\n",
    "    elif s == 3:\n",
    "        return 0.25\n",
    "    elif s == 2:\n",
    "        return 0.15\n",
    "    else:# s == 1:\n",
    "        return 0.09\n",
    "       \n",
    "def convertGWTG(df):\n",
    "    lstLow = []\n",
    "    lstHigh = []\n",
    "    df = df.reset_index()\n",
    "    idx = sorted(df.index)\n",
    "    for i in idx:\n",
    "        val = df.loc[i]['GWTG']\n",
    "        \n",
    "        if val == \"-\":\n",
    "            val = np.nan\n",
    "        elif \"-\" in str(val):\n",
    "            val = val.split('-')[0]\n",
    "            \n",
    "        val = float(val)\n",
    "\n",
    "        if np.isnan(val):\n",
    "            lstLow.append(np.nan)\n",
    "            lstHigh.append(np.nan)\n",
    "        elif val <= 33:\n",
    "            lstLow.append(0.01)\n",
    "            lstHigh.append(np.nan)\n",
    "        elif val >= 34 and val <= 50:\n",
    "            lstLow.append(0.01)\n",
    "            lstHigh.append(0.05)\n",
    "        elif val >= 51 and val <= 57:\n",
    "            lstLow.append(0.06)\n",
    "            lstHigh.append(0.10)\n",
    "        elif val >= 58 and val <= 61:\n",
    "            lstLow.append(0.11)\n",
    "            lstHigh.append(0.15)\n",
    "        elif val >= 62 and val <= 65:\n",
    "            lstLow.append(0.16)\n",
    "            lstHigh.append(0.20)\n",
    "        elif val >= 66 and val <= 70:\n",
    "            lstLow.append(0.21)\n",
    "            lstHigh.append(0.30)\n",
    "        elif val >= 71 and val <= 74:\n",
    "            lstLow.append(0.31)\n",
    "            lstHigh.append(0.4)\n",
    "        elif val >= 75 and val <= 78:\n",
    "            lstLow.append(0.41)\n",
    "            lstHigh.append(0.50)\n",
    "        else: #val >= 79\n",
    "            lstLow.append(0.51)\n",
    "            lstHigh.append(np.nan)\n",
    "    \n",
    "    return lstLow, lstHigh\n",
    "\n",
    "def makeScoreDF(dataset, labels, index, carnaScores=None):\n",
    "    #Get ESCAPE Score DF\n",
    "    orig = pd.read_csv(\"Calculated Scores/ESCAPE/\"+ dataset + \"_ESCAPE.csv\").set_index(index).sort_index()\n",
    "    lbls = makeLabels(orig, labels)\n",
    "    escDF = lbls\n",
    "    escDF['ESCAPE'] = orig[['ESCAPE']]\n",
    "    \n",
    "    missing = np.setdiff1d(labels.index, carnaScores.index)\n",
    "    scrs = convertCARNAEscape(orig, carnaScores, missing)\n",
    "    escDF['CARNA'] = scrs\n",
    "    \n",
    "    \n",
    "    #Make other scores DF\n",
    "    #ADHERE\n",
    "    orig = pd.read_csv(\"Calculated Scores/ADHERE/\"+ dataset + \"_ADHERE.csv\").set_index(index)\n",
    "    lbls = makeLabels(orig, labels)\n",
    "    scrDF = lbls\n",
    "    \n",
    "    scrDF[['ADHERE_Low','ADHERE_High']] = orig['ADHERE'].astype(str).str.split('-', expand=True).astype(float)\n",
    "    scrDF['ADHERE_Low'] = scrDF['ADHERE_Low'] / 100 #split and make btw 0 and 1\n",
    "    scrDF['ADHERE_High'] = scrDF['ADHERE_High'] / 100\n",
    "\n",
    "    #GWTG\n",
    "    try:\n",
    "        orig = pd.read_csv(\"Calculated Scores/GWTG/\"+ dataset + \"_GWTG.csv\").set_index(index)\n",
    "        low, high = convertGWTG(orig)\n",
    "        scrDF['GWTG_Low'] = low\n",
    "        scrDF['GWTG_High'] = high\n",
    "    except:\n",
    "        scrDF['GWTG_Low'] = np.nan\n",
    "        scrDF['GWTG_High'] = np.nan\n",
    "    \n",
    "    #MAGGIC\n",
    "    try:\n",
    "        orig = pd.read_csv(\"Calculated Scores/MAGGIC/\"+ dataset + \"_MAGGIC.csv\").set_index(index)\n",
    "        scrDF[\"MAGGIC Y1\"] = orig['Y1'] / 100\n",
    "        scrDF['MAGGIC Y3'] = orig['Y3'] / 100\n",
    "    except:\n",
    "        scrDF[\"MAGGIC Y1\"] = np.nan\n",
    "        scrDF['MAGGIC Y3'] = np.nan\n",
    "    \n",
    "    #Add Optimize and Effect scores\n",
    "    orig = pd.read_csv(\"Calculated Scores/OptimizeEffect/\"+ dataset + \"_optimizeEffectScore.csv\").set_index(index)\n",
    "    scrDF['OPTIMIZE-HF'] = orig['OPTIMIZE-HF']\n",
    "    scrDF['EFFECT 30 Day'] = orig['EFFECT 30 Day']\n",
    "    scrDF['EFFECT 1 Year'] = orig['EFFECT 1 Year']\n",
    "    \n",
    "    #Add SHFM\n",
    "    orig = pd.read_csv(\"Calculated Scores/SHF/\"+ dataset + \"_SHF.csv\").set_index(index).sort_index()\n",
    "    scrDF[\"SHFM Y1\"] = orig['SHF1'] / 100\n",
    "    scrDF['SHFM Y3'] = orig['SHF2'] / 100\n",
    "    scrDF[\"SHFM Y5\"] = orig['SHF5'] / 100\n",
    "    \n",
    "    scrs = convertCARNA(orig, carnaScores, missing)\n",
    "    scrDF['CARNA'] = scrs\n",
    "    \n",
    "\n",
    "    return escDF, scrDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84007635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAUC(df, scoreList):\n",
    "    precLst = []\n",
    "    rocLst = []\n",
    "    for score in scoreList:\n",
    "        dfCpy = df[df[score].notna()]\n",
    "        real = dfCpy['Real']\n",
    "        scoreVal = dfCpy[score]\n",
    "        \n",
    "        if not scoreVal.isnull().all():\n",
    "            rocAUC = roc_auc_score(real, scoreVal)\n",
    "            rocLst.append(rocAUC)\n",
    "        else:\n",
    "            rocLst.append(np.nan)\n",
    "    \n",
    "    return rocLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9bfbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://github.com/yandexdataschool/roc_comparison\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "#     print(\"Z is\", z)\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def calc_pvalueV2(aucs, sigma):\n",
    "    \"\"\"Computes p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       pvalue\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "#     print(\"Z is\", z)\n",
    "    return 2 * (1-scipy.stats.norm.cdf(z, loc=0, scale=1))\n",
    "#     return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    pvals = calc_pvalueV2(aucs, delongcov)\n",
    "    return aucs, delongcov, pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638fa65",
   "metadata": {},
   "source": [
    "# Risk Score Comparison\n",
    "Example steps for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ff35d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable defs\n",
    "datasets = ['ESCAPE','HF-ACTION', 'BEST', 'GUIDE-IT', 'CardShock', 'SerialCardiac']\n",
    "labels = [escapeLabels, hfactionLabels, bestLabels, guideLabels, cardShockLabels, serialLabels]\n",
    "index = ['DEIDNUM', 'ID', 'ID', 'ID','ID','ID']\n",
    "carnaScores = [escapeAllScores, hfactionAllScores, bestAllScores, guideAllScores]\n",
    "scoreList = ['ADHERE_Low', 'ADHERE_High', 'GWTG_Low', 'GWTG_High','MAGGIC Y1', 'MAGGIC Y3', 'OPTIMIZE-HF', \n",
    "             'EFFECT 30 Day','EFFECT 1 Year', 'SHFM Y1', 'SHFM Y3', 'SHFM Y5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7cb2d",
   "metadata": {},
   "source": [
    "### 1. For each patient record, get the risk score for each scoring method  \n",
    "    \n",
    "   If the score does not directly correlate to a probability of the outcome, convert it to the probability value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4667224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>ADHERE_Low</th>\n",
       "      <th>ADHERE_High</th>\n",
       "      <th>GWTG_Low</th>\n",
       "      <th>GWTG_High</th>\n",
       "      <th>MAGGIC Y1</th>\n",
       "      <th>MAGGIC Y3</th>\n",
       "      <th>OPTIMIZE-HF</th>\n",
       "      <th>EFFECT 30 Day</th>\n",
       "      <th>EFFECT 1 Year</th>\n",
       "      <th>SHFM Y1</th>\n",
       "      <th>SHFM Y3</th>\n",
       "      <th>SHFM Y5</th>\n",
       "      <th>CARNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99302</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99912</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99912</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Real  ADHERE_Low  ADHERE_High  GWTG_Low  GWTG_High  MAGGIC Y1  \\\n",
       "72        1       0.055        0.132      0.06       0.10      0.316   \n",
       "72        1       0.055        0.132      0.06       0.10      0.427   \n",
       "81        0       0.055        0.132      0.01       0.05      0.227   \n",
       "81        0       0.055        0.132      0.01       0.05      0.122   \n",
       "86        0         NaN          NaN       NaN        NaN        NaN   \n",
       "...     ...         ...          ...       ...        ...        ...   \n",
       "99302     1       0.021        0.023      0.01        NaN      0.111   \n",
       "99912     0         NaN          NaN       NaN        NaN        NaN   \n",
       "99912     0         NaN          NaN       NaN        NaN        NaN   \n",
       "99935     0       0.021        0.023      0.01       0.05      0.111   \n",
       "99935     0         NaN          NaN       NaN        NaN        NaN   \n",
       "\n",
       "       MAGGIC Y3  OPTIMIZE-HF  EFFECT 30 Day  EFFECT 1 Year  SHFM Y1  SHFM Y3  \\\n",
       "72         0.625         0.06          0.122          0.593     0.44     0.69   \n",
       "72         0.756         0.10          0.327          0.593     0.38     0.62   \n",
       "81         0.490         0.06          0.122          0.593     0.31     0.53   \n",
       "81         0.292         0.06          0.122          0.325     0.12     0.23   \n",
       "86           NaN         0.97          0.122          0.325     0.14     0.27   \n",
       "...          ...          ...            ...            ...      ...      ...   \n",
       "99302      0.269         0.97          0.034          0.129     0.10     0.19   \n",
       "99912        NaN         0.97          0.034          0.129     0.08     0.16   \n",
       "99912        NaN         0.97          0.034          0.129     0.05     0.10   \n",
       "99935      0.269         0.97          0.034          0.325     0.07     0.14   \n",
       "99935        NaN         0.97          0.004          0.129     0.15     0.28   \n",
       "\n",
       "       SHFM Y5  CARNA  \n",
       "72        0.96   0.25  \n",
       "72        0.93   0.25  \n",
       "81        0.88   0.25  \n",
       "81        0.53   0.25  \n",
       "86        0.58   0.15  \n",
       "...        ...    ...  \n",
       "99302     0.45   0.25  \n",
       "99912     0.39   0.15  \n",
       "99912     0.27   0.15  \n",
       "99935     0.35   0.25  \n",
       "99935     0.60   0.15  \n",
       "\n",
       "[866 rows x 14 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escapeDF, scoreDF = makeScoreDF(dataset='ESCAPE', labels=escapeLabels, index='DEIDNUM', carnaScores=escapeAllScores)\n",
    "scoreDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c72659",
   "metadata": {},
   "source": [
    "### 2. Calculate the AUC curve for each score prediction\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d33def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESCAPE</th>\n",
       "      <th>ADHERE_Low</th>\n",
       "      <th>ADHERE_High</th>\n",
       "      <th>GWTG_Low</th>\n",
       "      <th>GWTG_High</th>\n",
       "      <th>MAGGIC Y1</th>\n",
       "      <th>MAGGIC Y3</th>\n",
       "      <th>OPTIMIZE-HF</th>\n",
       "      <th>EFFECT 30 Day</th>\n",
       "      <th>EFFECT 1 Year</th>\n",
       "      <th>SHFM Y1</th>\n",
       "      <th>SHFM Y3</th>\n",
       "      <th>SHFM Y5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680515</td>\n",
       "      <td>0.594986</td>\n",
       "      <td>0.594986</td>\n",
       "      <td>0.596784</td>\n",
       "      <td>0.600587</td>\n",
       "      <td>0.639941</td>\n",
       "      <td>0.639941</td>\n",
       "      <td>0.430319</td>\n",
       "      <td>0.55016</td>\n",
       "      <td>0.548222</td>\n",
       "      <td>0.623452</td>\n",
       "      <td>0.622755</td>\n",
       "      <td>0.622373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ESCAPE  ADHERE_Low  ADHERE_High  GWTG_Low  GWTG_High  MAGGIC Y1  \\\n",
       "0  0.680515    0.594986     0.594986  0.596784   0.600587   0.639941   \n",
       "\n",
       "   MAGGIC Y3  OPTIMIZE-HF  EFFECT 30 Day  EFFECT 1 Year   SHFM Y1   SHFM Y3  \\\n",
       "0   0.639941     0.430319        0.55016       0.548222  0.623452  0.622755   \n",
       "\n",
       "    SHFM Y5  \n",
       "0  0.622373  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roclst = []\n",
    "rLst = getAUC(escapeDF, ['ESCAPE'])\n",
    "roclst.extend(rLst)\n",
    "    \n",
    "rLst = getAUC(scoreDF, scoreList)\n",
    "roclst.extend(rLst)\n",
    "    \n",
    "cols = ['ESCAPE', 'ADHERE_Low', 'ADHERE_High', 'GWTG_Low', 'GWTG_High',\n",
    "           'MAGGIC Y1', 'MAGGIC Y3', 'OPTIMIZE-HF', 'EFFECT 30 Day',\n",
    "           'EFFECT 1 Year', 'SHFM Y1', 'SHFM Y3', 'SHFM Y5']\n",
    "\n",
    "rocDF = pd.DataFrame([roclst], columns=cols)\n",
    "# rocDF = pd.DataFrame(roclst, columns=cols, index=datasets)\n",
    "rocDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7e6fb",
   "metadata": {},
   "source": [
    "### 3. Complete Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2747f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESCAPE</th>\n",
       "      <th>ADHERE_Low</th>\n",
       "      <th>ADHERE_High</th>\n",
       "      <th>GWTG_Low</th>\n",
       "      <th>GWTG_High</th>\n",
       "      <th>MAGGIC Y1</th>\n",
       "      <th>MAGGIC Y3</th>\n",
       "      <th>OPTIMIZE-HF</th>\n",
       "      <th>EFFECT 30 Day</th>\n",
       "      <th>EFFECT 1 Year</th>\n",
       "      <th>SHFM Y1</th>\n",
       "      <th>SHFM Y3</th>\n",
       "      <th>SHFM Y5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ESCAPE  ADHERE_Low  ADHERE_High  GWTG_Low  GWTG_High  MAGGIC Y1  MAGGIC Y3  \\\n",
       "0     0.0       0.256        0.256     0.271       0.23      0.033      0.033   \n",
       "\n",
       "   OPTIMIZE-HF  EFFECT 30 Day  EFFECT 1 Year  SHFM Y1  SHFM Y3  SHFM Y5  \n",
       "0        0.005          0.163          0.184      0.0      0.0      0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "#do escape score first\n",
    "miniDF = escapeDF[['Real', 'CARNA', 'ESCAPE']]\n",
    "miniDF = miniDF.fillna(0)\n",
    "aucs, delongcov, pvals = delong_roc_test(ground_truth=miniDF['Real'], predictions_one=miniDF['CARNA'], predictions_two=miniDF['ESCAPE'])\n",
    "lst.append(abs(pvals[0][0]))\n",
    "\n",
    "#do other scores\n",
    "for s in scoreList:        \n",
    "    miniDF = scoreDF[['Real', 'CARNA', s]]\n",
    "    miniDF = miniDF.dropna()\n",
    "#     miniDF = miniDF.fillna(0)\n",
    "\n",
    "    if len(miniDF.index) == 0: #all NAN\n",
    "        lst.append(np.nan)\n",
    "    else:\n",
    "        aucs, delongcov, pvals = delong_roc_test(ground_truth=miniDF['Real'], predictions_one=miniDF['CARNA'], predictions_two=miniDF[s])\n",
    "        lst.append(abs(pvals[0][0]))\n",
    "    \n",
    "    \n",
    "cols = ['ESCAPE', 'ADHERE_Low', 'ADHERE_High', 'GWTG_Low', 'GWTG_High','MAGGIC Y1', 'MAGGIC Y3', 'OPTIMIZE-HF', \n",
    "             'EFFECT 30 Day','EFFECT 1 Year', 'SHFM Y1', 'SHFM Y3', 'SHFM Y5']\n",
    "\n",
    "df = pd.DataFrame([lst], columns=cols)\n",
    "df = df.round(3)\n",
    "# df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c8241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cf92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48284421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b9343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22771699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_between_clfs(y_test, pred_proba_1, pred_proba_2, nsamples=1000):\n",
    "    auc_differences = []\n",
    "    auc1 = roc_auc_score(y_test.ravel(), pred_proba_1.ravel())\n",
    "    auc2 = roc_auc_score(y_test.ravel(), pred_proba_2.ravel())\n",
    "    observed_difference = auc1 - auc2\n",
    "    for _ in range(nsamples):\n",
    "        mask = np.random.randint(2, size=len(pred_proba_1.ravel()))\n",
    "        p1 = np.where(mask, pred_proba_1.ravel(), pred_proba_2.ravel())\n",
    "        p2 = np.where(mask, pred_proba_2.ravel(), pred_proba_1.ravel())\n",
    "        auc1 = roc_auc_score(y_test.ravel(), p1)\n",
    "        auc2 = roc_auc_score(y_test.ravel(), p2)\n",
    "        auc_differences.append(auc1 - auc2)\n",
    "    return observed_difference, np.mean(auc_differences >= observed_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e76822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obsDif, meanDif = permutation_test_between_clfs(y_test=miniDF['Real'], pred_proba_1=miniDF['CARNA'], pred_proba_2=miniDF['SHFM Y5'], nsamples=len(miniDF))\n",
    "\n",
    "# print(\"Observed Diff:\", obsDif, \"p(diff>=)\", meanDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5a1ab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESCAPE</th>\n",
       "      <th>ADHERE_Low</th>\n",
       "      <th>ADHERE_High</th>\n",
       "      <th>GWTG_Low</th>\n",
       "      <th>GWTG_High</th>\n",
       "      <th>MAGGIC Y1</th>\n",
       "      <th>MAGGIC Y3</th>\n",
       "      <th>OPTIMIZE-HF</th>\n",
       "      <th>EFFECT 30 Day</th>\n",
       "      <th>EFFECT 1 Year</th>\n",
       "      <th>SHFM Y1</th>\n",
       "      <th>SHFM Y3</th>\n",
       "      <th>SHFM Y5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ESCAPE  ADHERE_Low  ADHERE_High  GWTG_Low  GWTG_High  MAGGIC Y1  MAGGIC Y3  \\\n",
       "0     1.0       0.744        0.749     0.777      0.754      0.975      0.956   \n",
       "\n",
       "   OPTIMIZE-HF  EFFECT 30 Day  EFFECT 1 Year  SHFM Y1  SHFM Y3  SHFM Y5  \n",
       "0        0.005          0.893          0.881      1.0      1.0    0.997  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "#do escape score first\n",
    "miniDF = escapeDF[['Real', 'CARNA', 'ESCAPE']]\n",
    "miniDF = miniDF.fillna(0)\n",
    "obsDif, meanDif = permutation_test_between_clfs(y_test=miniDF['Real'], pred_proba_1=miniDF['CARNA'], pred_proba_2=miniDF['ESCAPE'], nsamples=len(miniDF))\n",
    "lst.append(meanDif)\n",
    "\n",
    "#do other scores\n",
    "for s in scoreList:        \n",
    "    miniDF = scoreDF[['Real', 'CARNA', s]]\n",
    "    miniDF = miniDF.dropna()\n",
    "#     miniDF = miniDF.fillna(0)\n",
    "\n",
    "    if len(miniDF.index) == 0: #all NAN\n",
    "        lst.append(np.nan)\n",
    "    else:\n",
    "        obsDif, meanDif = permutation_test_between_clfs(y_test=miniDF['Real'], pred_proba_1=miniDF['CARNA'], pred_proba_2=miniDF[s], nsamples=len(miniDF))\n",
    "        lst.append(meanDif)\n",
    "    \n",
    "    \n",
    "cols = ['ESCAPE', 'ADHERE_Low', 'ADHERE_High', 'GWTG_Low', 'GWTG_High','MAGGIC Y1', 'MAGGIC Y3', 'OPTIMIZE-HF', \n",
    "             'EFFECT 30 Day','EFFECT 1 Year', 'SHFM Y1', 'SHFM Y3', 'SHFM Y5']\n",
    "\n",
    "df = pd.DataFrame([lst], columns=cols)\n",
    "df = df.round(3)\n",
    "# df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0334feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}