{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Original DataFrames/AllDataSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Original DataFrames/HemoSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/AllDataCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/AllDataSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/AllDataHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Original DataFrames/AllDataBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/AllDataGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# escapeLabels[D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                               ESCAPE   HF-ACTION        BEST    GUIDE-IT  \\\nn                                 433        2130        2707         894   \nAge (years)                 56.1±13.9   58.6±12.7   60.2±12.3   61.5±13.9   \nGender (%, female)               25.9        28.1        21.9          68   \nRace (%, white[minority])  59.6[40.4]  62.1[37.9]  70.0[30.0]  54.8[45.2]   \nBMI                          28.4±6.7    31.0±7.1     0.0±0.0   14.9±16.2   \nEF                           19.3±6.6    25.4±7.4    23.0±7.3    24.1±8.2   \nHR                          80.8±14.9     0.0±0.0     0.0±0.0     0.0±0.0   \nBPSYS                      103.7±15.8  113.8±18.3  118.5±19.4  115.9±19.7   \nBPDIAS                      64.1±11.5   70.2±11.3   71.9±11.7   70.9±13.7   \nCRT                          6.7±34.0    2.5±37.4     1.2±0.4     1.5±0.6   \nPOT                           4.3±0.6     0.0±0.0     4.3±0.5     4.4±0.6   \nBUN                         36.3±22.5   24.9±27.9   24.6±15.3   26.5±19.7   \nSOD                         136.0±4.4     0.0±0.0   138.9±3.4   138.4±3.6   \nDeath                            0.27       0.165       0.317       0.173   \nRehosp                           0.57       0.124       0.629       0.412   \nReadm                           0.185       0.033         N/A         N/A   \n\n                          UVA Cardiogenic Shock UVA Serial Cath  \nn                                           364             183  \nAge (years)                           59.4±18.5      -23.6±27.2  \nGender (%, female)                         35.2            43.2  \nRace (%, white[minority])                   N/A             N/A  \nBMI                                    29.8±8.8      47.3±286.9  \nEF                                    31.7±17.4       31.3±18.0  \nHR                                      0.0±0.0         0.0±0.0  \nBPSYS                                111.1±21.9      109.1±21.4  \nBPDIAS                                62.2±15.5       59.9±17.2  \nCRT                                     1.7±1.3         1.7±1.0  \nPOT                                     0.0±0.0         0.0±0.0  \nBUN                                   34.9±24.2       39.1±25.7  \nSOD                                   136.9±5.1       135.7±5.2  \nDeath                                     0.566           0.415  \nRehosp                                      N/A             N/A  \nReadm                                       N/A             N/A  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESCAPE</th>\n      <th>HF-ACTION</th>\n      <th>BEST</th>\n      <th>GUIDE-IT</th>\n      <th>UVA Cardiogenic Shock</th>\n      <th>UVA Serial Cath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n</th>\n      <td>433</td>\n      <td>2130</td>\n      <td>2707</td>\n      <td>894</td>\n      <td>364</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>Age (years)</th>\n      <td>56.1±13.9</td>\n      <td>58.6±12.7</td>\n      <td>60.2±12.3</td>\n      <td>61.5±13.9</td>\n      <td>59.4±18.5</td>\n      <td>-23.6±27.2</td>\n    </tr>\n    <tr>\n      <th>Gender (%, female)</th>\n      <td>25.9</td>\n      <td>28.1</td>\n      <td>21.9</td>\n      <td>68</td>\n      <td>35.2</td>\n      <td>43.2</td>\n    </tr>\n    <tr>\n      <th>Race (%, white[minority])</th>\n      <td>59.6[40.4]</td>\n      <td>62.1[37.9]</td>\n      <td>70.0[30.0]</td>\n      <td>54.8[45.2]</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>BMI</th>\n      <td>28.4±6.7</td>\n      <td>31.0±7.1</td>\n      <td>0.0±0.0</td>\n      <td>14.9±16.2</td>\n      <td>29.8±8.8</td>\n      <td>47.3±286.9</td>\n    </tr>\n    <tr>\n      <th>EF</th>\n      <td>19.3±6.6</td>\n      <td>25.4±7.4</td>\n      <td>23.0±7.3</td>\n      <td>24.1±8.2</td>\n      <td>31.7±17.4</td>\n      <td>31.3±18.0</td>\n    </tr>\n    <tr>\n      <th>HR</th>\n      <td>80.8±14.9</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n    </tr>\n    <tr>\n      <th>BPSYS</th>\n      <td>103.7±15.8</td>\n      <td>113.8±18.3</td>\n      <td>118.5±19.4</td>\n      <td>115.9±19.7</td>\n      <td>111.1±21.9</td>\n      <td>109.1±21.4</td>\n    </tr>\n    <tr>\n      <th>BPDIAS</th>\n      <td>64.1±11.5</td>\n      <td>70.2±11.3</td>\n      <td>71.9±11.7</td>\n      <td>70.9±13.7</td>\n      <td>62.2±15.5</td>\n      <td>59.9±17.2</td>\n    </tr>\n    <tr>\n      <th>CRT</th>\n      <td>6.7±34.0</td>\n      <td>2.5±37.4</td>\n      <td>1.2±0.4</td>\n      <td>1.5±0.6</td>\n      <td>1.7±1.3</td>\n      <td>1.7±1.0</td>\n    </tr>\n    <tr>\n      <th>POT</th>\n      <td>4.3±0.6</td>\n      <td>0.0±0.0</td>\n      <td>4.3±0.5</td>\n      <td>4.4±0.6</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n    </tr>\n    <tr>\n      <th>BUN</th>\n      <td>36.3±22.5</td>\n      <td>24.9±27.9</td>\n      <td>24.6±15.3</td>\n      <td>26.5±19.7</td>\n      <td>34.9±24.2</td>\n      <td>39.1±25.7</td>\n    </tr>\n    <tr>\n      <th>SOD</th>\n      <td>136.0±4.4</td>\n      <td>0.0±0.0</td>\n      <td>138.9±3.4</td>\n      <td>138.4±3.6</td>\n      <td>136.9±5.1</td>\n      <td>135.7±5.2</td>\n    </tr>\n    <tr>\n      <th>Death</th>\n      <td>0.27</td>\n      <td>0.165</td>\n      <td>0.317</td>\n      <td>0.173</td>\n      <td>0.566</td>\n      <td>0.415</td>\n    </tr>\n    <tr>\n      <th>Rehosp</th>\n      <td>0.57</td>\n      <td>0.124</td>\n      <td>0.629</td>\n      <td>0.412</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>Readm</th>\n      <td>0.185</td>\n      <td>0.033</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [escapeAllData, hfactionAllData]\n",
    "labels = [escapeLabels, hfactionLabels]\n",
    "\n",
    "bigLst = []\n",
    "\n",
    "lst = [\"n\"]\n",
    "for d in labels:\n",
    "    lst.append(len(d))\n",
    "bigLst.append(lst)\n",
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "\n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    lst.append(\"N/A\")\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['HF-ACTION'] = getStats(hfactionAllData, hfactionLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                               ESCAPE   HF-ACTION        BEST    GUIDE-IT  \\\nn                                 433        2130        2707         894   \nAge (years)                 56.1±13.9   58.6±12.7   60.2±12.3   61.5±13.9   \nGender (%, female)               25.9        28.1        21.9          68   \nRace (%, white[minority])  59.6[40.4]  62.1[37.9]  70.0[30.0]  54.8[45.2]   \nBMI                          28.4±6.7    31.0±7.1     0.0±0.0   14.9±16.2   \nEF                           19.3±6.6    25.4±7.4    23.0±7.3    24.1±8.2   \nHR                          80.8±14.9     0.0±0.0     0.0±0.0     0.0±0.0   \nBPSYS                      103.7±15.8  113.8±18.3  118.5±19.4  115.9±19.7   \nBPDIAS                      64.1±11.5   70.2±11.3   71.9±11.7   70.9±13.7   \nCRT                          6.7±34.0    2.5±37.4     1.2±0.4     1.5±0.6   \nPOT                           4.3±0.6     0.0±0.0     4.3±0.5     4.4±0.6   \nBUN                         36.3±22.5   24.9±27.9   24.6±15.3   26.5±19.7   \nSOD                         136.0±4.4     0.0±0.0   138.9±3.4   138.4±3.6   \nDeath                            0.27        0.16        0.32        0.17   \nRehosp                           0.57        0.12        0.63        0.41   \nReadm                            0.18        0.03         N/A         N/A   \n\n                          UVA Cardiogenic Shock UVA Serial Cath  \nn                                           364             183  \nAge (years)                           59.4±18.5      -23.6±27.2  \nGender (%, female)                         35.2            43.2  \nRace (%, white[minority])                   N/A             N/A  \nBMI                                    29.8±8.8      47.3±286.9  \nEF                                    31.7±17.4       31.3±18.0  \nHR                                      0.0±0.0         0.0±0.0  \nBPSYS                                111.1±21.9      109.1±21.4  \nBPDIAS                                62.2±15.5       59.9±17.2  \nCRT                                     1.7±1.3         1.7±1.0  \nPOT                                     0.0±0.0         0.0±0.0  \nBUN                                   34.9±24.2       39.1±25.7  \nSOD                                   136.9±5.1       135.7±5.2  \nDeath                                      0.57            0.42  \nRehosp                                      N/A             N/A  \nReadm                                       N/A             N/A  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESCAPE</th>\n      <th>HF-ACTION</th>\n      <th>BEST</th>\n      <th>GUIDE-IT</th>\n      <th>UVA Cardiogenic Shock</th>\n      <th>UVA Serial Cath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n</th>\n      <td>433</td>\n      <td>2130</td>\n      <td>2707</td>\n      <td>894</td>\n      <td>364</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>Age (years)</th>\n      <td>56.1±13.9</td>\n      <td>58.6±12.7</td>\n      <td>60.2±12.3</td>\n      <td>61.5±13.9</td>\n      <td>59.4±18.5</td>\n      <td>-23.6±27.2</td>\n    </tr>\n    <tr>\n      <th>Gender (%, female)</th>\n      <td>25.9</td>\n      <td>28.1</td>\n      <td>21.9</td>\n      <td>68</td>\n      <td>35.2</td>\n      <td>43.2</td>\n    </tr>\n    <tr>\n      <th>Race (%, white[minority])</th>\n      <td>59.6[40.4]</td>\n      <td>62.1[37.9]</td>\n      <td>70.0[30.0]</td>\n      <td>54.8[45.2]</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>BMI</th>\n      <td>28.4±6.7</td>\n      <td>31.0±7.1</td>\n      <td>0.0±0.0</td>\n      <td>14.9±16.2</td>\n      <td>29.8±8.8</td>\n      <td>47.3±286.9</td>\n    </tr>\n    <tr>\n      <th>EF</th>\n      <td>19.3±6.6</td>\n      <td>25.4±7.4</td>\n      <td>23.0±7.3</td>\n      <td>24.1±8.2</td>\n      <td>31.7±17.4</td>\n      <td>31.3±18.0</td>\n    </tr>\n    <tr>\n      <th>HR</th>\n      <td>80.8±14.9</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n    </tr>\n    <tr>\n      <th>BPSYS</th>\n      <td>103.7±15.8</td>\n      <td>113.8±18.3</td>\n      <td>118.5±19.4</td>\n      <td>115.9±19.7</td>\n      <td>111.1±21.9</td>\n      <td>109.1±21.4</td>\n    </tr>\n    <tr>\n      <th>BPDIAS</th>\n      <td>64.1±11.5</td>\n      <td>70.2±11.3</td>\n      <td>71.9±11.7</td>\n      <td>70.9±13.7</td>\n      <td>62.2±15.5</td>\n      <td>59.9±17.2</td>\n    </tr>\n    <tr>\n      <th>CRT</th>\n      <td>6.7±34.0</td>\n      <td>2.5±37.4</td>\n      <td>1.2±0.4</td>\n      <td>1.5±0.6</td>\n      <td>1.7±1.3</td>\n      <td>1.7±1.0</td>\n    </tr>\n    <tr>\n      <th>POT</th>\n      <td>4.3±0.6</td>\n      <td>0.0±0.0</td>\n      <td>4.3±0.5</td>\n      <td>4.4±0.6</td>\n      <td>0.0±0.0</td>\n      <td>0.0±0.0</td>\n    </tr>\n    <tr>\n      <th>BUN</th>\n      <td>36.3±22.5</td>\n      <td>24.9±27.9</td>\n      <td>24.6±15.3</td>\n      <td>26.5±19.7</td>\n      <td>34.9±24.2</td>\n      <td>39.1±25.7</td>\n    </tr>\n    <tr>\n      <th>SOD</th>\n      <td>136.0±4.4</td>\n      <td>0.0±0.0</td>\n      <td>138.9±3.4</td>\n      <td>138.4±3.6</td>\n      <td>136.9±5.1</td>\n      <td>135.7±5.2</td>\n    </tr>\n    <tr>\n      <th>Death</th>\n      <td>0.27</td>\n      <td>0.16</td>\n      <td>0.32</td>\n      <td>0.17</td>\n      <td>0.57</td>\n      <td>0.42</td>\n    </tr>\n    <tr>\n      <th>Rehosp</th>\n      <td>0.57</td>\n      <td>0.12</td>\n      <td>0.63</td>\n      <td>0.41</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>Readm</th>\n      <td>0.18</td>\n      <td>0.03</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [escapeAllData, hfactionAllData]\n",
    "labels = [escapeLabels, hfactionLabels]\n",
    "\n",
    "bigLst = []\n",
    "\n",
    "lst = [\"n\"]\n",
    "for d in labels:\n",
    "    lst.append(len(d))\n",
    "bigLst.append(lst)\n",
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),2))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),2))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),2))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "\n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),2))\n",
    "    lst.append(\"N/A\")\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['HF-ACTION'] = getStats(hfactionAllData, hfactionLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          Death\nID             \nZ103426       0\nZ103697       0\nZ1050590      0\nZ1058186      1\nZ1059364      0\n...         ...\nZ93479        1\nZ93572        1\nZ937913       0\nZ958018       0\nZ98220        0\n\n[183 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Death</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Z103426</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Z103697</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Z1050590</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Z1058186</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Z1059364</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Z93479</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Z93572</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Z937913</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Z958018</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Z98220</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>183 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Age         0.00\nGender      0.00\nRace        0.00\nWt          5.77\nBMI         7.97\n           ...  \nPV         25.17\nMAP         3.70\nPP          3.70\nPPP         3.70\nPPRatio     4.16\nLength: 66, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get percent missing\n",
    "escapeAllData.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7.7787108964938065"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misData = escapeAllData\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7.330131920295854"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misData = serialAllData\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "12.03861927546138"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misData = escapeHemo\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5.858395989974937"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misData = cardShockHemo\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 56.1[13.9]\n",
      "Gender 0.259\n",
      "Race 0.596[0.404]\n"
     ]
    }
   ],
   "source": [
    "def getStats(data, labels):\n",
    "    if len(data) == len(labels) * 2:\n",
    "        print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        print(\"Gender\", round(gen[2.0],3))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        print(\"Race\", str(round(gen[1.0],3))+\"[\" + str(round(gen[2.0],3))+\"]\")\n",
    "    else:\n",
    "        print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        print(\"Gender\", round(gen[2.0],3))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        print(\"Race\", str(round(gen[1.0],3))+\"[\" + str(round(gen[2.0],3))+\"]\")\n",
    "    \n",
    "getStats(escapeAllData, escapeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 56.8[13.5]\n",
      "Gender 0.254\n",
      "Race 0.582[0.268]\n"
     ]
    }
   ],
   "source": [
    "getStats(escapeHemo, escapeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 58.6[12.7]\n",
      "Gender 0.281\n",
      "Race 0.621[0.379]\n"
     ]
    }
   ],
   "source": [
    "getStats(hfactionAllData, hfactionLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 60.2[12.3]\n",
      "Gender 0.219\n",
      "Race 0.7[0.3]\n"
     ]
    }
   ],
   "source": [
    "getStats(bestAllData, bestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 61.5[13.9]\n",
      "Gender 0.68\n",
      "Race 0.548[0.452]\n"
     ]
    }
   ],
   "source": [
    "getStats(guideAllData, guideLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsCard(data, labels):\n",
    "    print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    print(\"Gender\", round(gen[2.0],3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 59.4[18.5]\n",
      "Gender 0.117\n"
     ]
    }
   ],
   "source": [
    "getStatsCard(cardShockAllData, cardShockAllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: -23.6[27.2]\n",
      "Gender 0.432\n"
     ]
    }
   ],
   "source": [
    "getStatsCard(serialAllData, serialLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Age', 'Gender', 'Race', 'Wt', 'BMI', 'InitialHospDays',\n       'TotalHospDays', 'NYHA', 'MLHFS', 'AF', 'AlchE', 'ANGP', 'ARRH',\n       'CARREST', 'CVD', 'COPD', 'DEPR', 'DIAB', 'GOUT', 'HEPT', 'HTN',\n       'MALIG', 'RENAL', 'SMOKING', 'STERD', 'StrokeTIA', 'VAHD', 'VF', 'VHD',\n       'VT', 'ISCH', 'NonISCH', 'CABG', 'HTRANS', 'ICD', 'PACE', 'PTCI',\n       'SixFtWlk', 'VO2', 'ALB', 'ALT', 'AST', 'BUN', 'CRT', 'DIAL', 'HEC',\n       'HEM', 'PLA', 'POT', 'SOD', 'TALB', 'TOTP', 'WBC', 'ACE', 'BET', 'NIT',\n       'DIUR', 'EjF', 'BPDIAS', 'BPSYS', 'HR', 'PV', 'MAP', 'PP', 'PPP',\n       'PPRatio'],\n      dtype='object')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escapeAllData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training Averaged AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-e0baa42ce451>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mfpr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.027\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtpr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.946\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mroc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mauc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mfpr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"micro\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"micro\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mroc_curve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/HemoPheno4HF/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001B[0m in \u001B[0;36mauc\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0mCompute\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mrecall\u001B[0m \u001B[0mpairs\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdifferent\u001B[0m \u001B[0mprobability\u001B[0m \u001B[0mthresholds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m     \"\"\"\n\u001B[0;32m---> 79\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/HemoPheno4HF/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    250\u001B[0m     \"\"\"\n\u001B[1;32m    251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m     \u001B[0mlengths\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32min\u001B[0m \u001B[0marrays\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    253\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/HemoPheno4HF/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    250\u001B[0m     \"\"\"\n\u001B[1;32m    251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m     \u001B[0mlengths\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32min\u001B[0m \u001B[0marrays\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    253\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/HemoPheno4HF/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m_num_samples\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    189\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'shape'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Expected sequence or array-like, got <class 'float'>"
     ]
    }
   ],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}