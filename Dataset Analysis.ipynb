{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script reports statistics used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Original DataFrames/AllDataSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Original DataFrames/HemoSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/AllDataCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/AllDataSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Original DataFrames/AllDataBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/AllDataGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>EjF</th>\n",
       "      <th>RAP</th>\n",
       "      <th>PAS</th>\n",
       "      <th>PAD</th>\n",
       "      <th>PAMN</th>\n",
       "      <th>PCWP</th>\n",
       "      <th>CO</th>\n",
       "      <th>...</th>\n",
       "      <th>PP</th>\n",
       "      <th>PPP</th>\n",
       "      <th>PAPP</th>\n",
       "      <th>SVR</th>\n",
       "      <th>RAT</th>\n",
       "      <th>PPRatio</th>\n",
       "      <th>PAPi</th>\n",
       "      <th>SAPi</th>\n",
       "      <th>CPP</th>\n",
       "      <th>PRAPRat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEIDNUM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>5357.575758</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3509.677419</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1982.300885</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1772.043011</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>2621.138211</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98508</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99302</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.574713</td>\n",
       "      <td>2666.666667</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99302</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2440.251572</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>1.088608</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>3220.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1985.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Race   EjF   RAP   PAS   PAD  PAMN  PCWP    CO  ...  \\\n",
       "DEIDNUM                                                                ...   \n",
       "72       88.0     2.0   1.0  25.0  24.0  42.0  24.0  30.0  36.0  2.20  ...   \n",
       "72       88.0     2.0   1.0  25.0  18.0  42.0  24.0  30.0  24.0  3.10  ...   \n",
       "81       69.0     1.0   1.0  20.0  10.0  40.0  20.0  27.0  18.0  4.52  ...   \n",
       "81       69.0     1.0   1.0  20.0  12.0  35.0  15.0  25.0  17.0  4.65  ...   \n",
       "814      58.0     1.0   1.0   NaN   3.0  51.0  19.0  30.0  18.0  4.10  ...   \n",
       "...       ...     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "98508    57.0     1.0  98.0  30.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "99302    41.0     1.0   2.0  15.0  19.0  87.0  37.0  54.0  44.0  3.90  ...   \n",
       "99302    41.0     1.0   2.0  15.0  11.0  70.0  28.0  44.0  28.0  5.30  ...   \n",
       "99935    64.0     2.0   1.0  20.0   8.0  49.0  29.0  31.0  15.0  4.00  ...   \n",
       "99935    64.0     2.0   1.0  20.0   8.0  52.0  24.0  39.0  24.0  5.60  ...   \n",
       "\n",
       "           PP       PPP      PAPP          SVR       RAT   PPRatio       PAPi  \\\n",
       "DEIDNUM                                                                         \n",
       "72       28.0  0.245614  0.428571  5357.575758  0.666667  0.266667   0.750000   \n",
       "72       24.0  0.235294  0.428571  3509.677419  0.750000  0.272727   1.000000   \n",
       "81       17.0  0.212500  0.500000  1982.300885  0.555556  0.242857   2.000000   \n",
       "81       40.0  0.470588  0.571429  1772.043011  0.705882  0.571429   1.666667   \n",
       "814      34.0  0.354167  0.627451  2621.138211  0.166667  0.566667  10.666667   \n",
       "...       ...       ...       ...          ...       ...       ...        ...   \n",
       "98508     NaN       NaN       NaN          NaN       NaN       NaN        NaN   \n",
       "99302    54.0  0.486486  0.574713  2666.666667  0.431818  0.642857   2.631579   \n",
       "99302    86.0  0.623188  0.600000  2440.251572  0.392857  1.088608   3.818182   \n",
       "99935    94.0  0.676259  0.408163  3220.000000  0.533333  1.253333   2.500000   \n",
       "99935    72.0  0.615385  0.538462  1985.714286  0.333333  0.888889   3.500000   \n",
       "\n",
       "             SAPi   CPP    PRAPRat  \n",
       "DEIDNUM                             \n",
       "72       0.777778  50.0   1.166667  \n",
       "72       1.000000  50.0   1.333333  \n",
       "81       0.944444  45.0   1.700000  \n",
       "81       2.352941  45.0   3.333333  \n",
       "814      1.888889  44.0  11.333333  \n",
       "...           ...   ...        ...  \n",
       "98508         NaN  37.0        NaN  \n",
       "99302    1.227273  13.0   2.842105  \n",
       "99302    3.071429  13.0   7.818182  \n",
       "99935    6.266667  30.0  11.750000  \n",
       "99935    3.000000  30.0   9.000000  \n",
       "\n",
       "[418 rows x 28 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escapeHemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Get Patient Cohort Baseline Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESCAPE</th>\n",
       "      <th>BEST</th>\n",
       "      <th>GUIDE-IT</th>\n",
       "      <th>UVA Cardiogenic Shock</th>\n",
       "      <th>UVA Serial Cath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>433</td>\n",
       "      <td>2707</td>\n",
       "      <td>388</td>\n",
       "      <td>364</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age (years)</th>\n",
       "      <td>56.1±13.9</td>\n",
       "      <td>60.2±12.3</td>\n",
       "      <td>62.2±13.9</td>\n",
       "      <td>59.4±18.5</td>\n",
       "      <td>60.6±15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender (%, female)</th>\n",
       "      <td>25.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>66.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race (%, white[minority])</th>\n",
       "      <td>59.6[40.4]</td>\n",
       "      <td>70.0[30.0]</td>\n",
       "      <td>49.2[50.8]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>28.4±6.7</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>15.4±16.7</td>\n",
       "      <td>29.8±8.8</td>\n",
       "      <td>47.3±286.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EF</th>\n",
       "      <td>19.3±6.6</td>\n",
       "      <td>23.0±7.3</td>\n",
       "      <td>24.0±8.2</td>\n",
       "      <td>31.7±17.4</td>\n",
       "      <td>31.3±18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>80.8±14.9</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSYS</th>\n",
       "      <td>103.7±15.8</td>\n",
       "      <td>118.5±19.4</td>\n",
       "      <td>115.4±20.0</td>\n",
       "      <td>111.1±21.9</td>\n",
       "      <td>109.1±21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPDIAS</th>\n",
       "      <td>64.1±11.5</td>\n",
       "      <td>71.9±11.7</td>\n",
       "      <td>70.2±13.5</td>\n",
       "      <td>62.2±15.5</td>\n",
       "      <td>59.9±17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRT</th>\n",
       "      <td>6.7±34.0</td>\n",
       "      <td>1.2±0.4</td>\n",
       "      <td>1.6±0.7</td>\n",
       "      <td>1.7±1.3</td>\n",
       "      <td>1.7±1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POT</th>\n",
       "      <td>4.3±0.6</td>\n",
       "      <td>4.3±0.5</td>\n",
       "      <td>4.4±0.6</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>36.3±22.5</td>\n",
       "      <td>24.6±15.3</td>\n",
       "      <td>31.3±22.6</td>\n",
       "      <td>34.9±24.2</td>\n",
       "      <td>39.1±25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOD</th>\n",
       "      <td>136.0±4.4</td>\n",
       "      <td>138.9±3.4</td>\n",
       "      <td>138.3±3.8</td>\n",
       "      <td>136.9±5.1</td>\n",
       "      <td>135.7±5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Death</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rehosp</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Readm</th>\n",
       "      <td>0.185</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ESCAPE        BEST    GUIDE-IT  \\\n",
       "n                                 433        2707         388   \n",
       "Age (years)                 56.1±13.9   60.2±12.3   62.2±13.9   \n",
       "Gender (%, female)               25.9        21.9        66.2   \n",
       "Race (%, white[minority])  59.6[40.4]  70.0[30.0]  49.2[50.8]   \n",
       "BMI                          28.4±6.7     0.0±0.0   15.4±16.7   \n",
       "EF                           19.3±6.6    23.0±7.3    24.0±8.2   \n",
       "HR                          80.8±14.9     0.0±0.0     0.0±0.0   \n",
       "BPSYS                      103.7±15.8  118.5±19.4  115.4±20.0   \n",
       "BPDIAS                      64.1±11.5   71.9±11.7   70.2±13.5   \n",
       "CRT                          6.7±34.0     1.2±0.4     1.6±0.7   \n",
       "POT                           4.3±0.6     4.3±0.5     4.4±0.6   \n",
       "BUN                         36.3±22.5   24.6±15.3   31.3±22.6   \n",
       "SOD                         136.0±4.4   138.9±3.4   138.3±3.8   \n",
       "Death                            0.27       0.317       0.237   \n",
       "Rehosp                           0.57       0.629       0.518   \n",
       "Readm                           0.185         N/A         N/A   \n",
       "\n",
       "                          UVA Cardiogenic Shock UVA Serial Cath  \n",
       "n                                           364             183  \n",
       "Age (years)                           59.4±18.5       60.6±15.1  \n",
       "Gender (%, female)                         35.2            43.2  \n",
       "Race (%, white[minority])                   N/A             N/A  \n",
       "BMI                                    29.8±8.8      47.3±286.9  \n",
       "EF                                    31.7±17.4       31.3±18.0  \n",
       "HR                                      0.0±0.0         0.0±0.0  \n",
       "BPSYS                                111.1±21.9      109.1±21.4  \n",
       "BPDIAS                                62.2±15.5       59.9±17.2  \n",
       "CRT                                     1.7±1.3         1.7±1.0  \n",
       "POT                                     0.0±0.0         0.0±0.0  \n",
       "BUN                                   34.9±24.2       39.1±25.7  \n",
       "SOD                                   136.9±5.1       135.7±5.2  \n",
       "Death                                     0.566           0.415  \n",
       "Rehosp                                    0.475           0.787  \n",
       "Readm                                       N/A             N/A  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Get Percent Data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissing(misData):\n",
    "    return sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESCAPE: 7.8\n",
      "BEST: 2.0\n",
      "GUIDE IT: 15.1\n",
      "Card Shock: 10.4\n",
      "Serial: 7.3\n"
     ]
    }
   ],
   "source": [
    "# All Data\n",
    "print(\"ESCAPE:\", round(getMissing(escapeAllData),1))\n",
    "print(\"BEST:\", round(getMissing(bestAllData),1))\n",
    "print(\"GUIDE IT:\", round(getMissing(guideAllData),1))\n",
    "print(\"Card Shock:\", round(getMissing(cardShockAllData),1))\n",
    "print(\"Serial:\", round(getMissing(serialAllData),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESCAPE: 12.0\n",
      "Card Shock: 5.9\n",
      "Serial: 9.2\n"
     ]
    }
   ],
   "source": [
    "# Hemo\n",
    "print(\"ESCAPE:\", round(getMissing(escapeHemo),1))\n",
    "print(\"Card Shock:\", round(getMissing(cardShockHemo),1))\n",
    "print(\"Serial:\", round(getMissing(serialHemo),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get confidence intervals for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Return 95% Confidence Interval for Value\n",
    "def CI(val, n):\n",
    "    ci = 1.96 * math.sqrt(abs(val - (1 - val)) / n)\n",
    "    #return ci\n",
    "    return str(val) + \" +/- \" + str(round(ci,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.995 +/- 0.095\n"
     ]
    }
   ],
   "source": [
    "# Hemo - DeLvTx\n",
    "print(\"Accuracy\", CI(0.x, len(escapeHemo)))\n",
    "print(\"AUC\", CI(x, len(escapeHemo)))\n",
    "print(\"Sens\", CI(x, len(escapeHemo)))\n",
    "print(\"Spec\", CI(x, len(escapeHemo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hemo - Rehosp\n",
    "print(\"Accuracy\", CI(0.x, len(escapeHemo)))\n",
    "print(\"AUC\", CI(x, len(escapeHemo)))\n",
    "print(\"Sens\", CI(x, len(escapeHemo)))\n",
    "print(\"Spec\", CI(x, len(escapeHemo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.995 +/- 0.066\n",
      "AUC 0.871 +/- 0.057\n",
      "Sens 0.777 +/- 0.05\n",
      "Spec 0.972 +/- 0.065\n"
     ]
    }
   ],
   "source": [
    "# All Features - DeLvTx\n",
    "print(\"Accuracy\", CI(0.995, len(escapeAllData)))\n",
    "print(\"AUC\", CI(0.871, len(escapeAllData)))\n",
    "print(\"Sens\", CI(0.777, len(escapeAllData)))\n",
    "print(\"Spec\", CI(0.972, len(escapeAllData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.986 +/- 0.066\n",
      "AUC 0.795 +/- 0.051\n",
      "Sens 0.653 +/- 0.037\n",
      "Spec 0.948 +/- 0.063\n"
     ]
    }
   ],
   "source": [
    "# All Features - Rehosp\n",
    "print(\"Accuracy\", CI(0.986, len(escapeAllData)))\n",
    "print(\"AUC\", CI(0.795, len(escapeAllData)))\n",
    "print(\"Sens\", CI(0.653, len(escapeAllData)))\n",
    "print(\"Spec\", CI(0.948, len(escapeAllData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot Training Averaged AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}