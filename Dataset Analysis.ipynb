{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script reports statistics used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Original DataFrames/AllDataSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Original DataFrames/HemoSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/AllDataCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/AllDataSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Original DataFrames/AllDataBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/AllDataGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death</th>\n",
       "      <th>Rehosp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Z1017923</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1024990</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z104044</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1099417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1140320</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z888391</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z927126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z928524</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z93161</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z96296</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Death  Rehosp\n",
       "ID                     \n",
       "Z1017923      1       1\n",
       "Z1024990      1       0\n",
       "Z104044       1       1\n",
       "Z1099417      0       0\n",
       "Z1140320      1       1\n",
       "...         ...     ...\n",
       "Z888391       1       1\n",
       "Z927126       1       0\n",
       "Z928524       1       1\n",
       "Z93161        1       1\n",
       "Z96296        1       1\n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardShockHemoLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Get Patient Cohort Baseline Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESCAPE</th>\n",
       "      <th>BEST</th>\n",
       "      <th>GUIDE-IT</th>\n",
       "      <th>UVA Cardiogenic Shock</th>\n",
       "      <th>UVA Serial Cath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>433</td>\n",
       "      <td>2707</td>\n",
       "      <td>388</td>\n",
       "      <td>364</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age (years)</th>\n",
       "      <td>56.1±13.9</td>\n",
       "      <td>60.2±12.3</td>\n",
       "      <td>62.2±13.9</td>\n",
       "      <td>59.4±18.5</td>\n",
       "      <td>60.6±15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender (%, female)</th>\n",
       "      <td>25.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>66.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race (%, white[minority])</th>\n",
       "      <td>59.6[40.4]</td>\n",
       "      <td>70.0[30.0]</td>\n",
       "      <td>49.2[50.8]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>28.4±6.7</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>15.4±16.7</td>\n",
       "      <td>29.8±8.8</td>\n",
       "      <td>47.3±286.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EF</th>\n",
       "      <td>19.3±6.6</td>\n",
       "      <td>23.0±7.3</td>\n",
       "      <td>24.0±8.2</td>\n",
       "      <td>31.7±17.4</td>\n",
       "      <td>31.3±18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>80.8±14.9</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSYS</th>\n",
       "      <td>103.7±15.8</td>\n",
       "      <td>118.5±19.4</td>\n",
       "      <td>115.4±20.0</td>\n",
       "      <td>111.1±21.9</td>\n",
       "      <td>109.1±21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPDIAS</th>\n",
       "      <td>64.1±11.5</td>\n",
       "      <td>71.9±11.7</td>\n",
       "      <td>70.2±13.5</td>\n",
       "      <td>62.2±15.5</td>\n",
       "      <td>59.9±17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRT</th>\n",
       "      <td>6.7±34.0</td>\n",
       "      <td>1.2±0.4</td>\n",
       "      <td>1.6±0.7</td>\n",
       "      <td>1.7±1.3</td>\n",
       "      <td>1.7±1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POT</th>\n",
       "      <td>4.3±0.6</td>\n",
       "      <td>4.3±0.5</td>\n",
       "      <td>4.4±0.6</td>\n",
       "      <td>0.0±0.0</td>\n",
       "      <td>0.0±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>36.3±22.5</td>\n",
       "      <td>24.6±15.3</td>\n",
       "      <td>31.3±22.6</td>\n",
       "      <td>34.9±24.2</td>\n",
       "      <td>39.1±25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOD</th>\n",
       "      <td>136.0±4.4</td>\n",
       "      <td>138.9±3.4</td>\n",
       "      <td>138.3±3.8</td>\n",
       "      <td>136.9±5.1</td>\n",
       "      <td>135.7±5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Death</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rehosp</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Readm</th>\n",
       "      <td>0.185</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ESCAPE        BEST    GUIDE-IT  \\\n",
       "n                                 433        2707         388   \n",
       "Age (years)                 56.1±13.9   60.2±12.3   62.2±13.9   \n",
       "Gender (%, female)               25.9        21.9        66.2   \n",
       "Race (%, white[minority])  59.6[40.4]  70.0[30.0]  49.2[50.8]   \n",
       "BMI                          28.4±6.7     0.0±0.0   15.4±16.7   \n",
       "EF                           19.3±6.6    23.0±7.3    24.0±8.2   \n",
       "HR                          80.8±14.9     0.0±0.0     0.0±0.0   \n",
       "BPSYS                      103.7±15.8  118.5±19.4  115.4±20.0   \n",
       "BPDIAS                      64.1±11.5   71.9±11.7   70.2±13.5   \n",
       "CRT                          6.7±34.0     1.2±0.4     1.6±0.7   \n",
       "POT                           4.3±0.6     4.3±0.5     4.4±0.6   \n",
       "BUN                         36.3±22.5   24.6±15.3   31.3±22.6   \n",
       "SOD                         136.0±4.4   138.9±3.4   138.3±3.8   \n",
       "Death                            0.27       0.317       0.237   \n",
       "Rehosp                           0.57       0.629       0.518   \n",
       "Readm                           0.185         N/A         N/A   \n",
       "\n",
       "                          UVA Cardiogenic Shock UVA Serial Cath  \n",
       "n                                           364             183  \n",
       "Age (years)                           59.4±18.5       60.6±15.1  \n",
       "Gender (%, female)                         35.2            43.2  \n",
       "Race (%, white[minority])                   N/A             N/A  \n",
       "BMI                                    29.8±8.8      47.3±286.9  \n",
       "EF                                    31.7±17.4       31.3±18.0  \n",
       "HR                                      0.0±0.0         0.0±0.0  \n",
       "BPSYS                                111.1±21.9      109.1±21.4  \n",
       "BPDIAS                                62.2±15.5       59.9±17.2  \n",
       "CRT                                     1.7±1.3         1.7±1.0  \n",
       "POT                                     0.0±0.0         0.0±0.0  \n",
       "BUN                                   34.9±24.2       39.1±25.7  \n",
       "SOD                                   136.9±5.1       135.7±5.2  \n",
       "Death                                     0.566           0.415  \n",
       "Rehosp                                    0.475           0.787  \n",
       "Readm                                       N/A             N/A  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Get Percent Data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissing(misData):\n",
    "    return sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESCAPE: 7.8\n",
      "BEST: 2.0\n",
      "GUIDE IT: 15.1\n",
      "Card Shock: 10.4\n",
      "Serial: 7.3\n"
     ]
    }
   ],
   "source": [
    "# All Data\n",
    "print(\"ESCAPE:\", round(getMissing(escapeAllData),1))\n",
    "print(\"BEST:\", round(getMissing(bestAllData),1))\n",
    "print(\"GUIDE IT:\", round(getMissing(guideAllData),1))\n",
    "print(\"Card Shock:\", round(getMissing(cardShockAllData),1))\n",
    "print(\"Serial:\", round(getMissing(serialAllData),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESCAPE: 12.0\n",
      "Card Shock: 5.9\n",
      "Serial: 9.2\n"
     ]
    }
   ],
   "source": [
    "# Hemo\n",
    "print(\"ESCAPE:\", round(getMissing(escapeHemo),1))\n",
    "print(\"Card Shock:\", round(getMissing(cardShockHemo),1))\n",
    "print(\"Serial:\", round(getMissing(serialHemo),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot Training Averaged AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
