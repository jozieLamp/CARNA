{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data Validation/HF-ACTION/Original DataFrames/AllDataHF-ACTION.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 20>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m serialLabels \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mID\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msort_index()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m#HF-ACTION\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m hfactionAllData \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mData Validation/HF-ACTION/Original DataFrames/AllDataHF-ACTION.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msort_index()\n\u001B[1;32m     21\u001B[0m hfactionLabels \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mID\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msort_index()\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#BEST\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:934\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    931\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 934\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1218\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1214\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1217\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1228\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1229\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/PycharmProjects/CARNA/venv/lib/python3.8/site-packages/pandas/io/common.py:786\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    785\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 786\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    793\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    794\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    795\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Data Validation/HF-ACTION/Original DataFrames/AllDataHF-ACTION.csv'"
     ]
    }
   ],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Original DataFrames/AllDataSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Original DataFrames/HemoSingleValue.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/AllDataCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/AllDataSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/AllDataHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Original DataFrames/AllDataBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/AllDataGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# escapeLabels[D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [escapeAllData, hfactionAllData]\n",
    "labels = [escapeLabels, hfactionLabels]\n",
    "\n",
    "bigLst = []\n",
    "\n",
    "lst = [\"n\"]\n",
    "for d in labels:\n",
    "    lst.append(len(d))\n",
    "bigLst.append(lst)\n",
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),3))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "\n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),3))\n",
    "    lst.append(\"N/A\")\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['HF-ACTION'] = getStats(hfactionAllData, hfactionLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [escapeAllData, hfactionAllData]\n",
    "labels = [escapeLabels, hfactionLabels]\n",
    "\n",
    "bigLst = []\n",
    "\n",
    "lst = [\"n\"]\n",
    "for d in labels:\n",
    "    lst.append(len(d))\n",
    "bigLst.append(lst)\n",
    "\n",
    "def getStats(data, labels):\n",
    "    lst = []\n",
    "    \n",
    "    lst.append(len(labels))\n",
    "\n",
    "    if len(data) == len(labels) * 2:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        lst.append(round(gen[2.0]*100,1))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        lst.append(str(round(gen[1.0]*100,1))+\"[\" + str(round(gen[2.0]*100,1))+\"]\")\n",
    "        lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "        lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "        lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "        \n",
    "        lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "        lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "        lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),2))\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Rehosp']) / len(labels),2))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "    try:\n",
    "        lst.append(round(sum(labels['Readmission']) / len(labels),2))\n",
    "    except:\n",
    "        lst.append(\"N/A\")\n",
    "        \n",
    "        \n",
    "\n",
    "    return lst\n",
    "\n",
    "def getStatsCath(data, labels):\n",
    "    lst = []\n",
    "    lst.append(len(labels))\n",
    "    lst.append(str(round(data.describe()['Age'][1],1)) + \"±\" + str(round(data.describe()['Age'][2],1)))\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    lst.append(round(gen[2.0]*100,1))\n",
    "    lst.append(\"N/A\") #Race\n",
    "    lst.append(str(round(data.describe()['BMI'][1],1)) + \"±\" + str(round(data.describe()['BMI'][2],1)))\n",
    "    lst.append(str(round(data.describe()['EjF'][1],1)) + \"±\" + str(round(data.describe()['EjF'][2],1)))\n",
    "    lst.append(str(round(data.describe()['HR'][1],1)) + \"±\" + str(round(data.describe()['HR'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPSYS'][1],1)) + \"±\" + str(round(data.describe()['BPSYS'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BPDIAS'][1],1)) + \"±\" + str(round(data.describe()['BPDIAS'][2],1)))\n",
    "    \n",
    "    lst.append(str(round(data.describe()['CRT'][1],1)) + \"±\" + str(round(data.describe()['CRT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['POT'][1],1)) + \"±\" + str(round(data.describe()['POT'][2],1)))\n",
    "    lst.append(str(round(data.describe()['BUN'][1],1)) + \"±\" + str(round(data.describe()['BUN'][2],1)))\n",
    "    lst.append(str(round(data.describe()['SOD'][1],1)) + \"±\" + str(round(data.describe()['SOD'][2],1)))\n",
    "\n",
    "\n",
    "    lst.append(round(sum(labels['Death']) / len(labels),2))\n",
    "    lst.append(\"N/A\")\n",
    "    lst.append(\"N/A\")\n",
    "        \n",
    "    return lst\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=[\"n\", \"Age (years)\", \"Gender (%, female)\", \"Race (%, white[minority])\", \"BMI\", \"EF\", \"HR\", \"BPSYS\", \"BPDIAS\", \"CRT\", \"POT\", \"BUN\", \"SOD\", \"Death\", \"Rehosp\", \"Readm\"])\n",
    "df['ESCAPE'] = getStats(escapeAllData, escapeLabels)\n",
    "df['HF-ACTION'] = getStats(hfactionAllData, hfactionLabels)\n",
    "df['BEST'] = getStats(bestAllData, bestLabels)\n",
    "df['GUIDE-IT'] = getStats(guideAllData, guideLabels)\n",
    "df['UVA Cardiogenic Shock'] = getStatsCath(cardShockAllData, cardShockLabels)\n",
    "df['UVA Serial Cath'] = getStatsCath(serialAllData, serialLabels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(bigLst, columns=['idx','ESCAPE', 'HF-ACTION']).set_index(\"idx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "serialLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get percent missing\n",
    "escapeAllData.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "misData = escapeAllData\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "misData = serialAllData\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "misData = escapeHemo\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "misData = cardShockHemo\n",
    "sum(misData.isnull().sum()) / (misData.shape[0] * misData.shape[1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getStats(data, labels):\n",
    "    if len(data) == len(labels) * 2:\n",
    "        print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "        gen = data['Gender'].value_counts()/2/len(labels)\n",
    "        print(\"Gender\", round(gen[2.0],3))\n",
    "        gen = data['Race'].value_counts()/2/len(labels)\n",
    "        print(\"Race\", str(round(gen[1.0],3))+\"[\" + str(round(gen[2.0],3))+\"]\")\n",
    "    else:\n",
    "        print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "        gen = data['Gender'].value_counts()/len(labels)\n",
    "        print(\"Gender\", round(gen[2.0],3))\n",
    "        gen = data['Race'].value_counts()/len(labels)\n",
    "        print(\"Race\", str(round(gen[1.0],3))+\"[\" + str(round(gen[2.0],3))+\"]\")\n",
    "    \n",
    "getStats(escapeAllData, escapeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "getStats(escapeHemo, escapeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "getStats(hfactionAllData, hfactionLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "getStats(bestAllData, bestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "getStats(guideAllData, guideLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getStatsCard(data, labels):\n",
    "    print(\"Age:\", str(round(data.describe()['Age'][1],1)) + \"[\" + str(round(data.describe()['Age'][2],1)) + \"]\")\n",
    "    gen = data['Gender'].value_counts()/3/len(labels)\n",
    "    print(\"Gender\", round(gen[2.0],3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getStatsCard(cardShockAllData, cardShockAllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getStatsCard(serialAllData, serialLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "escapeAllData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot Training Averaged AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr = 0.027\n",
    "tpr = 0.946\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot and save averaged AUC graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.plot(fpr, tpr,\n",
    "     label='Averaged AUC: {0:0.3f}'\n",
    "           ''.format(roc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get Outcome Percentages Based on Cluster Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_AllData.csv\", sep=\",\", index_col='ID').sort_index() #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Preprocessed Data/ESCAPE_Hemo.csv\", sep=\",\", index_col='ID').sort_index() #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM').sort_index() #labels for prediction classes \n",
    "escapeHemoLabels = escapeLabels[escapeLabels.index.isin(escapeHemo.index)]\n",
    "\n",
    "#Cardiogenic Shock\n",
    "cardShockHemo = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockAllData = pd.read_csv(\"Data Validation/Cardiogenic Shock/Preprocessed Data/CardiogenicShock_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockHemoLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/HemoLabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "cardShockLabels = pd.read_csv(\"Data Validation/Cardiogenic Shock/Original DataFrames/LabelsCardiogenicShock.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Serial Cardiac\n",
    "serialHemo = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_Hemo.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialAllData = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Preprocessed Data/SerialCardiac_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialHemoLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/HemoLabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "serialLabels = pd.read_csv(\"Data Validation/Serial Cardiac Caths/Original DataFrames/LabelsSerialCardiac.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#HF-ACTION\n",
    "hfactionAllData = pd.read_csv(\"Data Validation/HF-ACTION/Preprocessed Data/HF-ACTION_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "hfactionLabels = pd.read_csv(\"Data Validation/HF-ACTION/Original DataFrames/LabelsHF-ACTION.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#BEST\n",
    "bestAllData = pd.read_csv(\"Data Validation/BEST/Preprocessed Data/BEST_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "bestLabels = pd.read_csv(\"Data Validation/BEST/Original DataFrames/LabelsBEST.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "\n",
    "#Guide it\n",
    "guideAllData = pd.read_csv(\"Data Validation/GUIDE-IT/Preprocessed Data/GUIDE-IT_AllData.csv\", sep=\",\", index_col='ID').sort_index()\n",
    "guideLabels = pd.read_csv(\"Data Validation/GUIDE-IT/Original DataFrames/LabelsGUIDE-IT.csv\", sep=\",\", index_col='ID').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPercentOutcome(dataset, labels, outcome, risk):\n",
    "    cluster = dataset.loc[dataset['Score' + outcome] == risk ]\n",
    "    labelMatches = labels[labels.index.isin(cluster.index)]\n",
    "    per = labelMatches[outcome].mean()\n",
    "    return per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeHemoLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeHemo, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockHemo, cardShockHemoLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialHemo, serialHemoLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Death'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "    per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "    per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1, per2, per3, per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE', 'Card Shock', 'Serial', 'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Rehosp'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "    per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "    per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, per5, per6])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION', 'BEST', 'GUIDE']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risks = [5, 4, 3, 2, 1]\n",
    "lst = []\n",
    "outcome = 'Readmission'\n",
    "for r in risks:\n",
    "    per1 = getPercentOutcome(escapeAllData, escapeLabels, outcome, r)\n",
    "#     per2 = getPercentOutcome(cardShockAllData, cardShockLabels, outcome, r)\n",
    "#     per3 = getPercentOutcome(serialAllData, serialLabels, outcome, r)\n",
    "    per4 = getPercentOutcome(hfactionAllData, hfactionLabels, outcome, r)\n",
    "#     per5 = getPercentOutcome(bestAllData, bestLabels, outcome, r)\n",
    "#     per6 = getPercentOutcome(guideAllData, guideLabels, outcome, r)\n",
    "    lst.append([r, per1,  per4, ])\n",
    "    \n",
    "df = pd.DataFrame(lst, columns = ['Cluster', 'ESCAPE',  'HF-ACTION']).set_index('Cluster')\n",
    "print(df.mean(axis=1))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}